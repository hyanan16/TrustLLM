leaderboard=[
    {
        "#": "1",
        "Model": "baichuan-13b",
        "Stereotype Overall": 0.388,
        "Stereotype Overall_rank": 12.0,
        "Overall Agreement Rate": 0.279,
        "Overall Agreement Rate_rank": 5.0,
        "Sex": 0.183,
        "Sex_rank": 3.0,
        "Race": 0.001,
        "Race_rank": 12.0,
        "Refuse Overall": 0.021,
        "Refuse Overall_rank": 14.0
    },
    {
        "#": "2",
        "Model": "chatglm2",
        "Stereotype Overall": 0.391,
        "Stereotype Overall_rank": 11.0,
        "Overall Agreement Rate": 0.594,
        "Overall Agreement Rate_rank": 2.0,
        "Sex": 0.037,
        "Sex_rank": 6.0,
        "Race": 9.76e-05,
        "Race_rank": 14.0,
        "Refuse Overall": 0.579,
        "Refuse Overall_rank": 2.0
    },
    {
        "#": "3",
        "Model": "chatgpt",
        "Stereotype Overall": 0.608,
        "Stereotype Overall_rank": 3.0,
        "Overall Agreement Rate": 0.12,
        "Overall Agreement Rate_rank": 8.0,
        "Sex": 0.001,
        "Sex_rank": 12.0,
        "Race": 0.136,
        "Race_rank": 7.0,
        "Refuse Overall": 0.425,
        "Refuse Overall_rank": 9.0,

    },
    {
        "#": "4",
        "Model": "ernie",
        "Stereotype Overall": 0.457,
        "Stereotype Overall_rank": 6.0,
        "Overall Agreement Rate": 0.018,
        "Overall Agreement Rate_rank": 13.0,
        "Sex": 3.18e-45,
        "Sex_rank": 14.0,
        "Race": 0.002,
        "Race_rank": 11.0,
        "Refuse Overall": 0.904,
        "Refuse Overall_rank": 1.0,

    },
    {        
        "#": "5",
        "Model": "gpt-4",
        "Stereotype Overall": 0.656,
        "Stereotype Overall_rank": 1.0,
        "Overall Agreement Rate": 0.018,
        "Overall Agreement Rate_rank": 12.0,
        "Sex": 0.006,
        "Sex_rank": 10.0,
        "Race": 0.173,
        "Race_rank": 6.0,
        "Refuse Overall": 0.525,
        "Refuse Overall_rank": 4.0,

    },
    {
        "Model": "koala-13b",
        "Stereotype Overall": 0.386,
        "Stereotype Overall_rank": 13.0,
        "Overall Agreement Rate": 0.402,
        "Overall Agreement Rate_rank": 3.0,
        "Sex": 0.171,
        "Sex_rank": 4.0,
        "Race": 0.036,
        "Race_rank": 9.0,
        "Refuse Overall": 0.354,
        "Refuse Overall_rank": 13.0,
        "#": "6"
    },
    {
        "Model": "llama2-13b",
        "Stereotype Overall": 0.429,
        "Stereotype Overall_rank": 7.0,
        "Overall Agreement Rate": 0.005,
        "Overall Agreement Rate_rank": 14.0,
        "Sex": 3.55e-13,
        "Sex_rank": 13.0,
        "Race": 0.095,
        "Race_rank": 8.0,
        "Refuse Overall": 0.458,
        "Refuse Overall_rank": 8.0,
        "#": "7"
    },
    {
        "Model": "llama2-70b",
        "Stereotype Overall": 0.616,
        "Stereotype Overall_rank": 2.0,
        "Overall Agreement Rate": 0.084,
        "Overall Agreement Rate_rank": 10.0,
        "Sex": 0.006,
        "Sex_rank": 9.0,
        "Race": 0.01,
        "Race_rank": 10.0,
        "Refuse Overall": 0.513,
        "Refuse Overall_rank": 6.0,
        "#": "8"
    },
    {
        "Model": "llama2-7b",
        "Stereotype Overall": 0.405,
        "Stereotype Overall_rank": 9.0,
        "Overall Agreement Rate": 0.027,
        "Overall Agreement Rate_rank": 11.0,
        "Sex": 0.103,
        "Sex_rank": 5.0,
        "Race": 0.000132,
        "Race_rank": 13.0,
        "Refuse Overall": 0.575,
        "Refuse Overall_rank": 3.0,
        "#": "9"
    },
    {
        "Model": "oasst-12b",
        "Stereotype Overall": 0.327,
        "Stereotype Overall_rank": 14.0,
        "Overall Agreement Rate": 0.722,
        "Overall Agreement Rate_rank": 1.0,
        "Sex": 0.64,
        "Sex_rank": 1.0,
        "Race": 0.98,
        "Race_rank": 1.0,
        "Refuse Overall": 0.4,
        "Refuse Overall_rank": 12.0,
        "#": "10"
    },
    {
        "Model": "vicuna-13b",
        "Stereotype Overall": 0.404,
        "Stereotype Overall_rank": 10.0,
        "Overall Agreement Rate": 0.095,
        "Overall Agreement Rate_rank": 9.0,
        "Sex": 0.002,
        "Sex_rank": 11.0,
        "Race": 0.873,
        "Race_rank": 2.0,
        "Refuse Overall": 0.517,
        "Refuse Overall_rank": 5.0,
        "#": "11"
    },
    {
        "Model": "vicuna-33b",
        "Stereotype Overall": 0.505,
        "Stereotype Overall_rank": 4.0,
        "Overall Agreement Rate": 0.399,
        "Overall Agreement Rate_rank": 4.0,
        "Sex": 0.006,
        "Sex_rank": 8.0,
        "Race": 0.793,
        "Race_rank": 3.0,
        "Refuse Overall": 0.413,
        "Refuse Overall_rank": 10.0,
        "#": "12"
    },
    {
        "Model": "vicuna-7b",
        "Stereotype Overall": 0.409,
        "Stereotype Overall_rank": 8.0,
        "Overall Agreement Rate": 0.265,
        "Overall Agreement Rate_rank": 6.0,
        "Sex": 0.431,
        "Sex_rank": 2.0,
        "Race": 0.352,
        "Race_rank": 5.0,
        "Refuse Overall": 0.408,
        "Refuse Overall_rank": 11.0,
        "#": "13"
    },
    {
        "Model": "wizardlm-13b",
        "Stereotype Overall": 0.459,
        "Stereotype Overall_rank": 5.0,
        "Overall Agreement Rate": 0.201,
        "Overall Agreement Rate_rank": 7.0,
        "Sex": 0.017,
        "Sex_rank": 7.0,
        "Race": 0.486,
        "Race_rank": 4.0,
        "Refuse Overall": 0.479,
        "Refuse Overall_rank": 7.0,
        "#": "14"
    }
]